

>  2021年5月22日23:05:57

1. 接口4和抽象类7的区别

   1. 抽象类不能被实例化，抽象类的方法可以有方法的实现

   2. 抽象类只能单继承

   3. 继承抽象类的子类需要实现抽象类的所有方法，否则只能定义为抽象类

   4. 抽象类的引用可以指向子类的实例

      > 接口

   5. 接口不能被实例化，抽象类不能有方法的实现，但是JDK1.8后可以有static方法和default方法；

   6. 接口中的变量为常量，即 public static final类型

   7. 实现接口的实现类需要实现接口的所有的方法，否则只能定义为抽象类

   8. 接口中只能有抽象方法；

   9. 接口可以多继承

   10. 接口可以多实现

   11. 接口的引用指向实现类的实例

2. 有哪几种IO模型？Java中常见的有什么？分别介绍一下？IO多路复用三个组件？三种实现方式？这三种方式的区别（4个角度）？

   同步阻塞、同步非阻塞、多路复用IO、信号驱动IO、异步IOselect  poll  epoll

   大小 1024  unlimit

   数据结构：  bitmap  数组 红黑树

   工作效率  on  on o1

3. volatile 关键字有什么用？能保证什么？如何实现缓存不一致问题（2）？

   能保证可见性 有序性    总线锁定 和 MESI



1. 为什么sleep 是Thread 中的方法，wait 是Object的方法(2个) 因为锁的等待和唤醒必须是同一把锁，又因为synchronized能锁任何对象，所以将可以被任何对象调用的方法写在object里

2. Spring 事务实现方式（4种）

   1. 编程式事务管理
   2. 声明式事务管理:基于XML的事务管理和基于Bean的事务管理、基于TransactionProxyFactoryBean方式

3. Redis 数据结构 底层数据结构

   ​	字符串 number raw     长度大于39字节 embstr

   ​	list 每个元素长度小于64且元素个数小于512 使用 ziplist，其他使用双向链表

   ​	hash 每个长度元素小于64且元素个数小于512使用ziplist，其他使用hash

   ​	set 所有元素都是整数且长度小于512 使用inset 其他使用hash

   ​	zset 每个元素长度小于64且元素个数小于128使用ziplist，其余使用**跳表**

4. HashMap 和 HashTable 区别 HashMap允许一个空键、多个空值，线程不安全；HashTable不允许空键和空值，线程安全。对get、put、remove加了synchronized

5. TreeMap 和 LinkedHashMap 区别 TreeMap 默认是按照键进行升序排序，LinkedHashMap按照put的顺序排序

6. Spring AOP 实现原理（2种）
   JDK的动态代理和 CGLib的动态代理

7. Spring bean的生命周期 实例化bean、设置相关属性、检查相关Aware接口并设置依赖、BeanPostProcessor 前置处理、检查是否是initialingBean以判断是否使用afterPropertySet、检查是否有init-method、BeanPostProcessor后置处理、设置destruction回调函数、使用、是否实现了了disposibleBean、是否配置有自定义的destroy方法。

8. Spring 使用的设计模式（工代单模包观适） 工厂模式、代理者模式、单例模式、模板方法模式、包装器模式、观察者模式、适配器模式

#### java创建对象的方式

new clone 反序列化 反射 unsafe

#### Spring事务传播机制

1. required 当前有，则加入；没有则新建
2. support 有则加入，没有则以非事务执行
3. mandatory 有则加入 没有则抛异常
4. required new 创建新事务，当前有事务则挂起
5. not support 以非事务执行，有则挂起
6. never 以非事务执行，有则抛异常
7. nested 当前有事务，在嵌套事务中执行，否则开启新事物

> 2021年5月31日20:46:06

1. 避免死锁的几种方式

   - 避免一个线程同时获得多把锁

   - 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只获得一种资源

   - 使用定时锁

   - 数据库连接时，加锁和解锁在一个连接中

2. Java对象头中都有什么，mark word中都有什么

   - Mark word 、对象指针，如果是对象数组，那还有数组长度
   - 同步状态 标识 hashcode GC 状态

3. Java 如何实现多态

   当有一个Father f = new Son()时，它会把f 存放在本地方法表中，然后将new出来的son放在堆中，f的类型放在了方法区中。然后虚拟机通过f的ref找到堆中的对象类型的指针，通过对象指针找到堆中的对象，查询方法表定位到实际的类执行，每个类有自己的方法表，一开始指向父类的方法，如果重写，就会覆盖父类的方法。

   方法表存在于方法区中。Object的任意一个方法，在子类的方法表中的位置是一样的，好处是jvm只需要指定是第几个方法就可以。

   方法区中也有运行时常量池。

> 2021年6月1日16:12:35

1. 线程池状态
   - running 
   - shutdown 
   - stop
   - tidying
   - terminated

>  2021年6月5日14:21:46

1. 什么时候使用聚簇索引

   1. 事务要搜索排序时
   2. 取范围数据时

2. 双亲委派的三次破坏

   1. ​	因为JDK1.0就存在classLoader() ，而JDK1.2才有了双亲委派，在此期间有用户自己定义了类加载实现代码，为了妥协，在JDK1.2以后，java.lang.ClassLoader中新增加了protected方法findclass
   2. 当基础类回调用户代码时。设计线程上下文加载器（Thread Context ClassLoader）
   3. 用户追求动态性导致

3. 什么情况下会立即初始化类

   1. 遇到new时
   2. 对类进行反射调用时
   3. 调用一个类，发现父类还没初始化时，先初始化父类
   4. 虚拟机启动时，指定需要启动的类，就是包含main方法的那个类，必须先初始化。
   5. 使用动态语言支持时。

4. 为什么使用双亲委派

   1. 可以避免一个类被多次加载，因为一个类被父类加载以后，子类就不会加载了
   2. 保证了安全性 因为Boostrap ClassLoader加载时，只会加载Java_home中的类，不会被随意替换。

5. Arrays.sort排序原理

   数组长度小于47采用插入排序

   47-286采用双轴快速排序

   大于286 且连续升序和连续降序性不好则采用改进的快速排序

   长度大于286，但是连续升序和连续降序性好，采用归并排序。

> 2021年6月9日17:09:09



> 2021年6月10日15:21:09

- 进程调度算法
  - 先来先服务
  - 最短作业优先
  - 高响应比优先
  - 时间片轮转
  - 最高优先级优先（两种方式）
  - 多级反馈队列
- 内存置换算法

> 2021年6月21日14:35:52

- 如何破坏单例模式

  - 通过反射（设置构造器accessable为true）和反序列化

- 如何防止破坏单例模式

  - 在构造器里判断是否为空，如果不为空，那就抛出异常
  - 单例模式中添加readResolve

  注：为什么反序列化的时候不能通过构造器判断对象是否为空；因为反序列化的构造器和自定义的构造器不是一个，反序列化的构造器不会调用自定义的构造器。

- 什么时候会立即初始化一个类

  - 遇到new putstatic getstatic invokestatic
  - 反射的时候
  - 初始化子类，发现父类没有初始化时，立即初始化父类
  - 虚拟机启动时，指定一个要执行的主类时（即包含main方法的类）

> 2021年6月26日21:05:56

- 为什么选择linux作为服务器

  1. 开源，因此可以对系统进行定制化
  2. 稳定性 ，同时如果需要修改系统配置，winserver需要重启系统，linux更改大多数配置无需重启，甚至更换内核都支持热切换
  3. 安全，linux只有特定用户或管理员才能访问内核，并且发现的漏洞很快就会得到修复
  4. 硬件 linux对硬件要求低
  5. 灵活，表现在对系统的完全控制
  6. 社区支持

- 为什么不用hash

  因为hash索引只包含哈希值和指针，因此不能使用覆盖索引

  索引数据不是按照索引值存储，因此不能用于排序

  不支持部分索引列匹配查找，如果索引是AB, 如果查询的时候只有A,则无法使用索引

  不支持范围查询

  存在hash冲突

- 索引优点

  减少了服务器需要扫描的数据量

  避免排序和临时表

  将随机IO变为顺序IO

- 进程和线程区别

  进程是资源分配的最小单位，线程是CPU调度的最小单位

  进程间上下文切换资源开销大，线程之间切换上下文资源开销小

  一个进程可以有多个线程，一个线程只能属于一个进程

  一个进程崩溃，由于保护机制，不会影响其他进程；而一个线程崩溃，整个进程就崩溃了

  同一个进程的线程共享进程的地址空间，而进程之间地址空间是独立的

- linux修改用户权限方法？？？？

- 索引缺点

  - 创建和维护索引要耗费时间，这种时间随数据量的增加而增加
  - 索引占用物理空间，如果是聚簇索引，需要的空间更大
  - 对表进行增加删除修改后的时候，索引也需要动态地维护，降低了数据维护速度。

> 2021年6月28日15:55:39

- TCP最大连接数

  - 如果是客户端，最大连接数是受ip_local_port_range限制，同时受限于65535，但是可以配置多ip扩展连接数
  - 服务端，理论上如果不考虑地址重用，tcp最大连接数为2^32 * 2 ^16次方。最大连接数取决于内存，每条静止的TCP连接大约占3.3k内存

  受限于文件句柄限制和端口限制

  因为Linux操作系统下所有都是文件，因此每个TCP连接都占一个文件描述符，通过ulimit -n 可以查看本机最大可打开文件数。可以通过 ulimit -n 100000 设置文件描述符最大为10w。

- 文件描述符作用

- HTTPS加密过程

  - 首先是非对称加密，客户端申请连接，服务端把公钥发送给客户端，同时自己有一把私钥，客户端收到公钥后，自己随机生成一个私钥，把生成的私钥通过公钥加密后发送给服务器，服务器收到加密后的客户端的私钥后，用自己的私钥解密，然后就可以通过客户端生成的私钥进行对称加密从而通信了。
  - 对称密钥包括DES、Triple DES、RC2、RC4

- SSL握手

  1. 交换协议版本号
  2. 选择一个两端都了解的密码
  3. 对两端的身份进行认证
  4. 生成临时的会话密钥，以便加密信道

  详细流程：

  客户端发送Client Hello 发送内容： 支持的协议版本、加密方法、压缩方法和客户端随机数

  服务端发送ServerHello 发送内容：确认的加密版本、加密方法、服务器证书和服务器随机数

  客户端回应 验证证书，如果证书过期、域名不一致或者不是由可信机构颁布，则弹出警告；如果没有问题，则从证书中取出服务器公钥； 发送内容：premasterkey随机数、编码改变通知、客户端握手结束通知（这是前面发送所有内容的hash）

  服务端最后回应  发送内容：编码改变通知，服务器握手结束通知，也是前边发送的所有内容的hash

- Http1.0和http1.1区别

  1. **缓存处理**  http1.0主要使用header里的If-Modified-Since，Expires作为标准，HTTP1.1引入更多缓存控制策略，如Entity tag，If-Unmodified-Since,If-Match, If-No-Match
  2. **带宽优化和网络连接的使用** Http1.0存在带宽浪费的现象，例如客户端只需要对象的一部分，而服务器却返回了整个对象，并且不支持断点续传；Http1.1在请求头引入了Range头域，允许请求部分资源，返回码是206
  3. **错误通知的管理** Http1.1增加了24个错误码，如409 表示请求资源和资源当前状态冲突，410 服务器某资源被永久删除。
  4. **Host头处理**  在Http1.0认为每个主机和唯一一个Ip绑定，因此请求中没有host主机。而随着虚拟主机技术发展，一台宿主机可能存在多台虚拟主机，且共享同一个Ip，需要通过Host 区分，因此增加了Host。
  5. **长连接** Http1.1支持长连接和请求流水线处理，一个TCP连接可以传多个Http请求和响应，减少了建立和关闭连接的消耗和延迟，Http1.1默认开启Connection： Keep-Alive，一定程度弥补了Http1.0每次请求创建连接的缺点。

- SPDY(speedy)

  SPDY是谷歌2012年提出的针对Http1.x优化的方案

  1. **降低延迟**，采用多路复用技术
  2. **设置优先级** 采用多路复用可能导致关键请求阻塞，因此SPDY允许给每个request设置优先级。
  3. **header压缩** 由于Http1.1很多请求是重复的，因此选择合适的压缩算法可以减少包的大小和数量
  4. **基于Https的加密协议传输** 
  5. **服务端推送** 会将css文件相对应的js文件推送给客户端，当需要js文件的时候无需请求，直接从缓存中获取即可。

> 2021年6月29日14:38:33

- 什么是回表

  mysql有两大类索引，聚集索引和普通索引，聚集索引的叶子结点存储的是行数据，而普通索引存储的是主键值，当使用到一个普通索引时，获取到主键值，此时回到聚集索引中，再根据主键值进行查询，这个从普通索引树到聚集索引树的过程就叫回表。

  innodb有且只有一个聚集索引：

  如果有PK，PK就是聚集索引

  没有PK，则找第一个唯一非空的列作为聚集索引

  如果没有唯一非空，则创建一个隐藏的row-id作为聚集索引。

- count(1)和count(*)  count (列)区别

  count(1)和count(*)一样，没有性能上的差异，而count(列)返回的是结果集中不为null的行的数量，更建议使用count(\*)  因为这是Sql92定义的标准统计行数语法

> 2021年6月30日19:59:21

- 为什么timewait需要2msl

  为了保证A发送的最后一个ACK报文能到达B。这个ACK可能会丢失，如果B收不到，那么就会重传ACK + FIN, 最多需要2MSL就可以到达A, 如果A在timewait不等待，发送完直接关闭，无法收到B重传的ack + fin，也就无法再次重传确认报文，就会导致B无法正常关闭。

  A在发送完ACK后，经过2msl时间，就可以使本连接持续时间所产生的所有报文都可以在网络上消失，就不会导致一个新的连接出现旧的连接请求报文段了。

- sql语句的执行顺序

  from - join - on - where - group by - avg ,sum- having -select-distinct- order by -limit

- mysql 的sql语句执行过程

  1. **连接数据库** 客户端发送一条查询语句，服务端的**连接管理模块**收到请求，将请求转发给**连接进线程模块**，调用**用户模块**进行授权检查，通过后，连接进线程模块从线程连接池中取出空闲的被缓存的连接线程和客户端请求对接，如果失败则创建一个新的连接请求
  2. **处理请求**  查询缓存，通过一个大小写敏感的哈希查找判断查询是否命中查询缓存数据-> 查询优化处理将SQL转为一个执行计划，这个计划首先解析和预处理，生成一棵解析数，判断语法是否合法，然后将语法树转为执行任务，并选择最小的成本执行计划，然后查询执行引擎。
  3. **返回结果**  如果查询可以被缓存，则将结果放在缓存中，然后把结果返回给客户端，返回是一个逐步返回的过程，产生第一个结果后，就可以向服务器返回结果集，然后封包，使用TCP协议传输数据。

> 2021年7月1日23:19:18

- Redis内存淘汰策略

  volatile-lru： 从设置过期时间的数据集中挑选最近最少使用的数据淘汰。没有设置过期时间的key不会被淘汰

  volatile-ttl：从设置过期时间的数据集中挑选将要过期的数据淘汰

  volatile-random: 从设置过期时间的数据集中任意选择数据淘汰。

  allkeys-lru: 从所有的数据集中挑选最近最少使用的数据淘汰

  allkeys-random: 从所有的数据集中选择任意数据淘汰

  no-enviction: 禁止淘汰数据，当内存不足以容纳数据时，新写入操作就会报错，请求可以继续进行。

> 2021年7月5日15:19:26

- SpringBoot自动装配原理

  SpringBoot项目启动是通过SpringBootApplication注解实现的，这个SpringBootApplication注解相当于SpringBootConfiguration、EnableAutoConfiguration、ComponentScan三个注解，其中EnableAutoConfiguration是关键，它启动了自动配置，内部实际上是去加载META-INF/spring.facorties文件的信息，然后筛选出以EnableAutoConfiguration为Key的数据，加载到IOC中，实现自动装配。

- TOPK问题

  1. 直接排序
  2. 快速排序： 因为快速排序每次都会确定一个元素在它的最终位置，那么就判断当前元素所在的位置是不是k，如果是，那就直接返回，如果发现比k小，那么mid = right - 1, 否则mid = left + 1;
  3. K次最值选择 缺点： 内存可能不够
  4. 堆排序

- TCC是什么

  ​	TCC是用于分布式事务问题的，TCC是指Try、Confirm、Cancel。

  ​	在日常的开发中，一个操作可能会涉及修改多个数据库，例如在商城中，一笔订单可能需要涉及到扣款，减库存，加积分，通知发货等等，有可能发生付款完成但是库存减失败的情况，为避免这种情况发生，需要保证事务的一致性，TCC的操作是当有订单产生的时候，并不是直接减掉库存，而是在冻结库存这个新增字段增加将订单中商品数量，同时减掉库存数量，其他库也是一样，当所有的操作完成后，TCC框架会执行confirm，就会将冻结的库存减掉，如果发生意外，像服务器崩掉，就会执行cancel，那么就将冻结库存的数量转移到实际库存字段，实现了事务的一致性。

- String a = new String("123") 创建了几个对象

  两个 ，编译阶段判断"123"是否存在，不存在则创建常量对象"123", 通过new 关键字在堆中创建了一个String对象 

- String a = "123" + "456" 创建了几个对象

  一个，JVM编译阶段将123和456合并为123456

- String a = "123" + new String("456");

  创建了四个对象，"123" , "456"两个常量对象，一个new String("456") 堆对象，还有一个堆对象 "123456";

- 运行时常量池位于哪儿

  方法区

- 方法区中存储什么

  虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码。

- GCRoot都有什么

  虚拟机栈引用的对象，方法区中静态属性引用的对象，常量引用的对象，Native方法引用的对象

- 字符串常量池 Class常量池 运行时常量池

  字符串常量池，又叫全局字符串池，是类加载验证准备完成后，在堆内生成字符串常量对象，然后将字符串实例的引用存在了字符串常量池。在HotSpotVM实现字符串常量池是通过StringTable这个Hash表。StringTable是放在方法区的，因此它被所有的线程共享。

  Class常量池，class文件除了包含类的版本、字段、方法、接口、字段等信息，还有一个信息是常量池，这个常量池存放了各种字面量和符号引用。字面量就是字符串或者被final修饰的变量。符号引用是一组符号用来描述所引用的目标。符号引用包含类和接口的全限定名、字段的名称和描述符、方法的名称和描述符。Java在编译时，不会像C++和C一样有链接这个步骤，而是虚拟机加载文件的时候动态链接，他需要一个中间层来转换目前地址和真是地址，class常量是就是这个中间层，当虚拟机运行时，需要从class常量池获得对应的符号引用，在类的创建时解析翻译到具体的内存地址上。

  运行时常量池，在类加载完成后，将class常量池的符号引用转存到运行时常量池中，每个class都有一个运行时常量池，类在解析完成后，将符号引用转为直接引用。

> 2021年7月6日09:50:48

- 线程状态
  - 初始化 NEW
  - 运行 RUNNABLE
  - 阻塞 BLOCKED
  - 等待 WAITING （不见不散）
  - 超时等待 TIMED_WAITING （过时不候）
  - 终止 TERMINATED

- 调用start方法一定会立即创建线程吗？
  - 不一定，因为start最终调用的是native方法，这个取决于操作系统此时是否是空闲的，如果是，那么就立即创建，如果不是，那么可能需要延迟创建

- Lock和Synchronized区别
  1. Lock是一个接口，而synchronized是关键字，synchronized是内置语言实现的
  2. 发生异常的时候，synchronized会自动释放锁，而Lock不会，这就可能导致死锁。
  3. Lock可以让等待锁的线程相应中断，synchronized不行，使用sync等待的线程会一直等待下去。
  4. 通过Lock可知道有没有获取到锁，sync不行
  5. Lock可以提高多个线程进行读操作的效率

> 2021年7月7日10:52:23

- 集合线程不安全解决办法
  - Vector  -> 通过List\<String> list = new Vector<>(); 因为vector的add方法加了sync关键字
  - Collections   ->  List\<String> list = Collections.synchronizedList(new ArrayList<>());
  - CopyOnWriteArrayList ->   List\<String> list  = new CopyOnWriteArrayList<>(); 写时复制技术。并发读，add元素时，首先复制一份新的数组，然后在新的数组中添加元素，最后将新的数组覆盖掉原来的数组
  - <img src="C:\Users\SenseChuang\AppData\Roaming\Typora\typora-user-images\image-20210707110507820.png" alt="image-20210707110507820" style="zoom:67%;" />
  - HashSet 解决方法： CopyOnWriteHashSet
  - HashMap解决方法： ConcurrentHashMap

- synchronized实现同步的基础：Java的每个对象都可以作为锁
  - 普通同步方法，锁当前实例对象
  - 静态同步方法，锁当前类的class对象
  - 同步代码块，锁synchronized括号里配置的对象

- 非公平锁，公平锁
  - 非公平锁： 线程饿死，效率高
  - 公平锁： 阳光普照，效率低

- 死锁

   两个或两个以上的进程，在执行过程中，因为争夺资源而造成的一种互相等待的现象，如果没有外力的干涉，他们无法再执行下去。

  原因： 系统资源不足，进程运行推进顺序不合适，资源分配不当。

- 验证死锁

  - jps
  - jstack   JVM自带的堆栈跟踪工具

- 读锁和写锁哪个会发生死锁

  都会发生死锁

![image-20210707165344379](C:\Users\SenseChuang\AppData\Roaming\Typora\typora-user-images\image-20210707165344379.png)

![image-20210707173525508](C:\Users\SenseChuang\AppData\Roaming\Typora\typora-user-images\image-20210707173525508.png)

只有读完成后，才能写，写操作可以读。

> 2021年7月9日20:54:21

- TCP四层各层的作用

  应用层 决定了向用户提供应用服务时通信的活动 ，如DNS，FTP

  传输层 提供处于网络连接中两台计算机之间的数据传输。 TCP UDP

  网络层 处理网络上流动的数据包

  链路层 处理连接网络的硬件部分 

- ARP协议

  ​	Address Resolution Protocol 地址解析协议，用于实现IP地址到Mac地址的转换。首先通过广播的方式发送数据包，数据包中包含自己的IP和Mac地址，当对应的IP主机收到以后就把自己的Mac地址返回源主机，由于原数据包包含IP和Mac地址，因此可以采用单播形式

  ​	ARP数据包中包含源IP，源Mac， 目标IP，目标Mac（全0表示请求），操作码（1请求，2 回应

  ​	ARP属于哪一层？ 因为最终目的是为了获取Mac，服务于链路层，从这个考虑属于数据链路层；但ARP基于Ethernet协议，Ip也基于Ethernet，IP属于网络层，Arp也应属于网络层。

- HTTP请求报文内容

  请求方式、URI、协议版本、请求头、内容实体

- 响应报文内容

  协议版本、状态码、状态码的原因短语、响应头、主体

- HTTP 头部内容

  ​	分为四部分

  - 通用首部字段 CCTTDUVWP

    Cache-Control Date Via Warning  Prama Upgrade Trailer Connection Transfer-Encoding

  - 请求首部字段  HAAAAIIIIIFERPUR

    Host、Accept 、Accpet-Charset、Accept-Encoding、 Accept-Language 、If-Match 、If-No-Match 、If-Modified-Since、If-Unmodified-Since、 If-Range、From、 Except、 Range 、 Proxy-Authuration、 User-Agent 、Referer、Max-Forward 
    
  - 响应首部字段 AApleRSVW

    Accpet-Ranges、Age、ETag、 Location、 Proxy-Authenticate、 Retry-After、Server、Vary、WWW-Authenticate

  - 实体首部字段ACCCCCCCEL

    ​	Allow、Content-Encoding、Content-Language、Content-Length、Content-Location、Content-MD5、Content-Range、Content-Type、Expires、Last-Modified



> 2021年7月11日15:36:18

- Https加密过程
  1. 客户端发送Client Hello开始SSL通信，报文中包含客户端支持的SSL指定版本、加密组件列表
  2. 服务端回复Server Hello ，内容包含SSL版本和加密组件
  3. 然后服务端继续发送证书，证书包含公开密钥
  4. 服务端发送Server Hello Done
  5. 客户端回应Client Key Master 生成preMaster secret ,CKM 已经经过公开密钥加密
  6. 客户端回应Change Cipher Spec 报文，表明以后将使用pre master secret加密
  7. 客户端回应Finished报文，报文包含连接至今全部报文的整体校验值。握手协商是否成功，要以服务器能否正确解密Finished报文为标准
  8. 服务器发送Change Cipher Spec报文
  9. 服务器发送Finished报文
  10. 服务器和客户端的Finished报文交换完毕，表明SSL连接建立
  11. 应用层协议通信
  12. 客户端断开连接，发送Close-Notify报文

> 2021年7月12日10:29:50

- SPDY特点

  1. 多路复用
  2. 服务器主动推送
  3. 赋予请求优先级
  4. 压缩头部
  5. 服务器提示功能

- XSS攻击

  XSS跨站脚本攻击是指通过存在安全漏洞的Web网站注册用户的浏览器运行非法的HTML标签或JavaScript进行的一种攻击

- SQL注入攻击

  针对web应用使用的数据库，通过运行非法的sql而产生的的攻击

- CSRF 跨站点请求伪造

  攻击者通过设置好的陷阱，强制对已完成认证的用户进行非预期的个人信息或者设定信息等某些状态更新。属于被动攻击

> 2021年7月13日09:12:38

- 令牌桶和漏桶

  漏桶是保证每秒处理的速度一致，而令牌桶不仅能够限制处理速度，还能应对突发情况。

  因为漏桶每秒处理请求的数量是固定的，多出来的直接溢出，而令牌桶是固定时间放令牌，有请求的时候则取令牌，如果某一个时间有突发，则可以一次取走多个令牌，保证突发。

  令牌桶是为了保护自己，主要是对调用者限流。

  漏桶为了保护别人，保证自己调用别人的接口时速度一样。

> 2021年7月13日16:55:45

- HashMap 如何计算hash值

  取key的hashcode，使之右移16位，然后将右移的结果和原hashcode做异或。

  为什么？

  因为它需要对散列值取余计算所在的桶的位置，如果只取最后几位，碰撞就会很严重。并且如果散列本身做的不好，分布上有等差漏洞，碰撞会更加严重。因此需要借助hashcode的前16位来进行扰动，增加随机性。

  为什么是异或而不是或？

  对于每一个均匀输入，异或结果为0概率为50%，为1概率为50%， 而或为0的概率为25%，为1概率为75%。

- hashmap如何实现自定义容量的

  调用的tableSizeFor实现的。

  通过不断与右移1、2、4、8、16位的数进行或操作实现的。

- 当在hashmap构造函数中传入一个map会发生什么？

  首先获取参数map的size，然后判断table 是否为空，如果为空，那么就计算它的容量，计算方式是size / loadfactor + 1  然后判断这个容量是否大于最大容量，如果大于那么就取最大，如果小，就去取容量。然后判断计算后的容量是否大于阈值，大于则增大阈值。如果table不为空，判断是否大于阈值，大于，就扩容。最后将参数map的所有元素都放到新的map中

- putval 过程中发生了什么

  如果key值计算出的桶位置为空，则直接将新节点放在该位置

  如果不为空，判断对应桶第一个元素的key是否与给定的相等，如果相等，那么就记录这个结点。如果是树节点，调用putTreeVal，如果是链表，遍历这个链表，如果找到key相等的node，就记录这个节点，如果没找到，就创建一个新的节点，将kv赋值给新创建的结点。在这个过程中可能发生链表到红黑树的转换。再然后判断标记的结点是否为空，如果不为空，说明已存在结点，那么就直接覆盖原结点。最后modcount++ 并判断是否需要扩容。

  ```java
  final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                     boolean evict) {
          Node<K,V>[] tab; Node<K,V> p; int n, i;
          if ((tab = table) == null || (n = tab.length) == 0)
              n = (tab = resize()).length;
          if ((p = tab[i = (n - 1) & hash]) == null)
              tab[i] = newNode(hash, key, value, null);
          else {
              Node<K,V> e; K k;
              if (p.hash == hash &&
                  ((k = p.key) == key || (key != null && key.equals(k))))
                  e = p;
              else if (p instanceof TreeNode)
                  e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
              else {
                  for (int binCount = 0; ; ++binCount) {
                      if ((e = p.next) == null) {
                          p.next = newNode(hash, key, value, null);
                          if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                              treeifyBin(tab, hash);
                          break;
                      }
                      if (e.hash == hash &&
                          ((k = e.key) == key || (key != null && key.equals(k))))
                          break;
                      p = e;
                  }
              }
              if (e != null) { // existing mapping for key
                  V oldValue = e.value;
                  if (!onlyIfAbsent || oldValue == null)
                      e.value = value;
                  afterNodeAccess(e);
                  return oldValue;
              }
          }
          ++modCount;
          if (++size > threshold)
              resize();
          afterNodeInsertion(evict);
          return null;
      }
  ```

- Resize过程中发生了什么

  首先判断原始容量是不是大于0，如果大于0且原始容量大于等于最大容量，将阈值设置为最大容量，然后直接返回；如大于0 但是原始容量小于最大容量并且原始容量大于默认初始容量，那么新的阈值为原阈值的2倍。如果原阈值大于0，说明在构造函数中指定了初始容量，并将阈值赋给初始容量。如果阈值等于0，说明没指定，那么就使用默认的容量和阈值。然后根据容量 * 加载因子计算指定了容量下的阈值。再然后开始复制链表，遍历整个OldTab，判断数组中的链表是不是只有一个，也就是有没有next，如果只有一个，那么就根据e.hash() & (newCap - 1) 计算出所在的位置，如果是树，调用树的split方法。如果是链表，新建四个节点，判断e.hash() & oldCap 是否为0，如果是0，那么就接在loTail上，如果为1，则接在highTail上，直到原链表全部完成，最后将lowHead放在原位置，highHead 放在原位置 +  原table 容量的位置。

> 2021年7月14日19:29:21

- 如何保证缓存与数据库双写时的数据一致性？

  1. 先更新数据库，后更新缓存

     ​		有的业务需求缓存中的值并不直接从数据库中拿，而是经过计算得的缓存值，这个时候更新缓存代价很大。如果这个时候有大量写数据，但是读请求不多，如果每次都更新，性能消耗很大。

  2. 先更新数据库，后删除缓存

     ​		可能存在更新完数据库后，缓存删不掉的情况，就会导致脏数据。可以使用消息队列进行删除的补偿。但是又会导致代码耦合严重，因此可以采用订阅数据库的binlog日志，对缓存进行操作。

  3. 先更新缓存，后更新数据库

     与情况1一致。

  4. 先删除缓存，后更新数据库

     可能存在读不到数据或者读到旧数据问题。可以采用延时双删策略。但延时双删也有问题，如果使用读写分离的架构，那么主从同步之间也会有信息差。解决办法是强制将其指向主库进行查询。

> 2021年7月15日09:47:14

- volatile和synchronized区别

  1. volatile关键字只能修饰变量，synchronized关键字只能用于代码块和方法
  2. volatile会禁止指令重排，syn不会
  3. volatile本质是告诉JVM当前变量在工作内存的值是不确定的，需要从主存中取，而sync则是锁住当前变量，只有当前线程能访问，其他线程会被阻塞
  4. volatile不会造成线程阻塞，sync会
  5. volatile 不能保证原子性，只能保证有序性和可见性，syn都能保证

- 如何解决脏读、不可重复读和幻读

  **脏读** 瞬间共享读锁和排他写锁

  **不可重复读** 共享读锁和排他写锁

  幻读
  
- 如何防止接口被恶刷

  加验证码，针对手机号过滤，限制Ip，由于ip信息是存在请求头的，https对请求本身加密，可以防止ip被伪造或篡改采用https

- 网站访问慢，如何优化

  首先判断是网络原因还是服务器内部原因，如果是网络原因，可以采用：

  ​	采用gzip

	使用CDN
	
   使用较小的图像

	 减少页面发出的请求 可以通过懒加载

  如果是系统内部原因，可以分库，或删除无用的CSS

- nginx 如何做负载均衡

  **轮询**

  **weight**

  **指定轮询几率**

  **ip_hash**   如果用户登录后使用负载均衡重定向到另一台服务器，登录信息可能丢失，因此可以采用iphash根据hash算法自动定位到服务器。

  **fair**  按后端响应时间分配，响应时间段的先分配

  **url_hash** 按访问的url的hash分配。使每个url指向同一个后端服务器。

- 保存用户的登录状态

  首先设置sessionId为所需要保持的时长，然后将sessionId存到cookie里，每次在登录界面的时候获取cookie然后获取sessionId，发送到服务器，校验session是否过期。

- nginx重写url

  通过rewrite 规则 定向路径 重写类型，规则可以是字符串或者正则表达式，定向路径表示匹配后定向的路径， 重写类型 last(表示完成write) break(本条匹配完成，终止匹配，不再匹配后续规则，浏览器地址栏不变)  redirect(返回302重定向，浏览器URL为跳转后的) permanent(301永久重定向，地址栏会显示跳转后的url)

  **last 和rewrite区别 ：** last在server 和if中，break使用location中；last不终止后续url匹配，break会。

> 2021年7月16日09:51:13

### 泛型

泛型使得数据类别可以像参数一样由外部传递，更符合面向对象开发。提供了类型检查机制，只有类型匹配才能正常赋值，能提高软件安全性。提高了代码的可读性，不必等运行时强制转换。

虚拟机没有泛型，泛型是在编译器这个层次实现的。使用泛型的时候加上类型参数，编译的时候去掉，这个过程叫类型擦除。

在生成的Java字节码中不包含泛型中的类型信息。并不存在List\<String> .class 而只有List.class 

 ？  为无限定通配符，表示？代表的是位置类型，因此涉及到？操作时，一定与具体类型无关，相当于提供了只读功能，只保留与具体类型无关的功能。

在泛型被擦除的时候，如果泛型类中的类型参数部分没有指定上线，会被转为Object，如果指定了上限，会转为类型上限。

泛型不接受8种数据类型

不能创建具体类型的泛型数组  因为类型擦除带来的影响，所有类型信息被擦除，无法分辨数组元素类型是哪一种，也就无法分配内存空间。

**为什么要类型擦除?**

为了向后兼容，保证1.5的程序能在8.0上运行。本质上是为了让非泛型的Java程序在后续支持泛型的JVM上运行。

**为什么类型擦除能保持向后兼容？**

之前非泛型的写法，编译成的字节码是A，之后的泛型写法，只是在A的前后插入了其他汇编码，不会破坏A的整体。

> 2021年7月18日23:03:51

## 线程间通信机制

#### 共享内存

线程之间共享程序的公共状态，通过写读内存中的公共状态进行隐式通信

#### 消息传递

线程之间没有公共状态，线程之间通过发送消息显式通信。

Java采用共享内存方式。

> 2021年7月20日10:46:17

## 项目优化

1. 动静分离
2. 开启缓存
3. 提高日志级别

## Redis锁

首先可以采用synchronized方法锁当前对象，但是可能会存在问题，在集群情况下，可能会造成锁多个。

然后可以使用nx命令，通过设置一个坑位，获取到锁，然后删除，但是在锁删除的时候，断电了，可能会导致删不掉，因此可以设置锁自动过期。但是需要保证设置锁过期时间的与加锁是同一个操作。还有个问题是如果业务代码执行时间过长，就会导致删除的时候是别人的锁。因此可以设置UUID，匹配的时候是自己的所才能删除。这样又会存在问题，就是在获取到返回值的时候，别人设置了新的锁，会导致返回的结果是对的，但是此时Redis已经是别人设置的Id了，会导致删除失败，因此可以采用lua脚本的方式进行原子性删除。

 ## Redisson

watch dog默认加锁为30秒时间，时间不够自动续期 

加锁的业务只要运行完成，就不会给 当前锁续期，即使不手动解锁，锁也会在30秒自动删除。

如果指定释放时间，它会发送redis执行脚本，进行占锁，默认时间就是指定的时间

如果没有指定超时时间，就是用30 *1000 ms，只要占锁成功，就会启动定时任务，重新设置新的过期时间，新的过期时间就是看门狗的默认时间，每隔十秒执行一次。(internalLockLeaseTime / 3 = 10s)

#### Redis信号量

**停车**

指定一个固定值，每次去acquire，如果获取到了，那么就执行后续操作，并将固定值减一，如果没有获取到，就一直阻塞，直到获取到。执行完毕可以通过release 释放锁，并将固定值加一。

同时可以使用tryAcquire，如果为true表示获取到，然后减一；如果没有获取到，就返回false。

#### CountDownLatch

**锁门**

只有当数据为0 的时候，才会执行业务代码，否则会一直阻塞。

![image-20210720194438166](C:\Users\SenseChuang\AppData\Roaming\Typora\typora-user-images\image-20210720194438166.png)

## mysql主从复制

模式：一主一从，一主多从，多主一从、双主复制、级联复制

设计三个线程： log dump thread（主节点）、IO线程（从节点）、SQL 线程（从节点）

主库生成一个log dump线程， 用来给从库IO线程传binlog，从库的IO会请求主库的Binlog，然后将binlog写到relay log，sql线程读取relay log，并解析成SQL执行。

### log dump thread线程

当从节点连接到主节点时，会创建一个log dump线程，当读取binlog时，log dump会给主节点的binlog加锁，当读取完成后释放锁，主节点会给每个从节点都分配一个线程

### IO线程

从节点执行start slave后，从节点会创建一个IO线程连接主节点来申请读取binlog日志，主节点发送日志，然后会把日志保存到relay log中

**relaylog 中包含** max_relay_log_size, relay_log_purge（是否自动清空不再需要中继日志）, relay_log_recover（从库宕机，导致部分中级日志未处理完，自动放弃所有relaylog）

### sql 线程

解析reloy log数据并执行

### 主从复制模式介绍

#### 异步模式

客户端发送数据到主库，主库处理后立即返回给客户端，但是并不主动推送给从服务器，就有一个问题，主节点崩溃，刚更新的数据没有同步到从服务器，如果强行将从提升到主服务器，可能导致数据不完整。

#### 半同步模式

接收到客户端的数据后，并不直接返回，而是等至少一个从节点收到并写到relaylog中才返回，只能保证一个节点，否则就需要等待，直到到达超时时间后切换为异步模式再提交。需要master 和slave安装插件。

#### 全同步模式

主库执行完一个事务，等待所有从库都复制并且执行完才返还给客户端。

#### GTID模式

global transaction identifier :全局事务id，一个事务对应一个gtid，保证每个主库上提交的事务在集群中有唯一的id。

不再需要根据binlog和位点确定从库要执行的事务的方式。

**流程：** 

1. master 更新数据，在事务前生成GTID，然后记录到binlog
2. slave IO线程将变更的binlog写入到relay log，根据gtid读取，告诉slave下一个执行的gtid
3. sql线程从relaylog获取gtid，然后对比slave端binlog是否有记录，有的话则忽略，没有则执行记录到binlog

#### 主从复制步骤

1. 主服务器新增账号并分配权限，查看master状态 记录日志名称和行号
2. 修改从服务器的master信息，然后重启，查看io 和sql线程是否为yes

### 搭建canal

1. 修改mysql的配置，设置serverid，使用 show master status记录日志，设置binlog格式为row

2. 使用docker 拉取canal，运行

3. 进入canal内部，修改容器中canal配置文件，包括数据库地址密码，binlog名称，行号，注意去除serveid前的注释

4. 然后查看日志，是否报错，如果报错如图，说明虚拟机的CPU为1核，需要提高虚拟机配置，增加为2核

   ![image-20210721105817813](C:\Users\SenseChuang\AppData\Roaming\Typora\typora-user-images\image-20210721105817813.png)

>  2021年7月22日18:16:49

### mybatis的动态sql 标签有哪些

if test 、choose whentest otherwise、where(知道只有在一个以上的if条件有值的情况下才插入where，并且如果是以or或者and开头，where标签也知道如何去除)、set（用于动态包含需要更新的列）

### Redis函数

#### String

get set getrange getset setex setnx setrange 

#### hash

hset hsetnx hget hexists hkeys hgetall

#### list

lpush lpop lrange lpushx

#### set

sadd scard {sdiff k1 k2 k3（保留k1中k2和k3没有的元素）}  {sinter k1 k2(取k1和k2的交集)} {sunion k1 k2  得到s1和s2的并集}

#### zset

zadd k score member , zcard key ,zcount key start stop 得 到集合key中分值在start和stop之间的元素

### 线程切换

就绪 --> 运行 : 分配到时间片的时候

运行 -->就绪：分配的时间片运行结束或者有更高优先级的线程执行

运行 ---> 阻塞： 当等待IO完成或者请求外设等资源的使用和分配时

阻塞 ---> 就绪： IO结束完成后

### Redis String类型的最大容量

512M

### Redis String是安全的吗

是的，它只关心二进制化的字符串，不关心具体格式，只会严格按照二进制的数据存取，不会妄图以某种特殊格式解析数据。

它的string类型中通过定义字节数组、使用的长度、未使用的长度来减少内存分配时间，提高了速度。

#### Redis主从复制优点

数据冗余 故障恢复 负载均衡 高可用

延迟和数据不一致问题 数据过期问题 复制超时 复制中断

### Mysql 优化分页

1. 使用子查询优化，先定位偏移位置的id，然后往后查询
2. 使用id限定优化，假设id是连续的，可以根据查询的页数和记录数计算出id 的范围，饭后使用between  and，但只能是在有id主键的情况下
3. 使用临时表优化 当id断掉的情况下，使使用临时存储的表记录分页的id，使用分页id进行in查询。

